{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7107a0b-c005-4c11-8a53-2507bc1ef06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a2bb41f-efc3-452e-91cc-438aa80793bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emanjavacas/MacBERTh were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "m = AutoModel.from_pretrained('emanjavacas/MacBERTh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abaef4bc-df92-4e51-acbe-d3f1b5a7debe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = AutoTokenizer.from_pretrained('emanjavacas/MacBERTh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85fdfca3-e696-460f-83e5-5d13e5c54ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "550bc152-d67c-4383-8bf3-830b4b7feaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./Leiden/Datasets/OED/data/oed-quotes-subset.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "316740ae-ef56-42b3-a83b-b5b23e1818db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = data['quote'].values[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "afd65b99-e392-4e5e-9493-d817b62fdeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = tok(list(sents), return_tensors='pt', padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33bc6da7-b809-481d-a178-d1ea9079a18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    2,   960,  1148,   859,  9690,  1529,   873, 11036,   842,    16,\n",
       "           878,   905,  3333,   549,   839,   828, 13716,   833, 17292,  2870,\n",
       "           549,   839, 14307,    30,   911,   924,   905,   914,  1466,   844,\n",
       "          1049, 27431,   565,    18,     3],\n",
       "        [    2,   869,   915,   944,   868,   881,  5267,   549,   844, 17091,\n",
       "            16,   911,  1200,   549,   844,    43, 27431,  6477,    18,     3,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "31553f8b-929d-4c2e-8b99-0bcaca6dc08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state', 'pooler_output'])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = m(**ids)\n",
    "output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3bac3e1a-4752-4f5a-baf1-e169f82ac32f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state', 'pooler_output', 'hidden_states'])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = m(**ids, output_hidden_states=True)\n",
    "output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dcd9c535-9837-4be3-9b2a-5336100a531a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([2, 35, 768])\n",
      "1 torch.Size([2, 35, 768])\n",
      "2 torch.Size([2, 35, 768])\n",
      "3 torch.Size([2, 35, 768])\n",
      "4 torch.Size([2, 35, 768])\n",
      "5 torch.Size([2, 35, 768])\n",
      "6 torch.Size([2, 35, 768])\n",
      "7 torch.Size([2, 35, 768])\n",
      "8 torch.Size([2, 35, 768])\n",
      "9 torch.Size([2, 35, 768])\n",
      "10 torch.Size([2, 35, 768])\n",
      "11 torch.Size([2, 35, 768])\n",
      "12 torch.Size([2, 35, 768])\n"
     ]
    }
   ],
   "source": [
    "for idx, out in enumerate(output['hidden_states']):\n",
    "    print(idx, out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8a070b9d-e219-480d-a01c-49a1f4f13028",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent2 = \"God hath no suche bodyly membres, as this membres to the lettre dothe pretende to shewe: but all this was done in great mistery.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c4443a27-b59a-477d-be5b-1f26b9d84b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'God hath no suche bodyly membres, as this membres to the lettre dothe pretende to shewe: but all this was done in great mistery.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a02e0191-b546-4871-a0f3-e0974a1e648a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids2 = tok([sent2], return_tensors='pt', padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "89e7f034-22a3-401f-958d-906b88239983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'god': [[1]],\n",
       "             'hath': [[2]],\n",
       "             'no': [[3]],\n",
       "             'suche': [[4]],\n",
       "             'bodyly': [[5, 6]],\n",
       "             'membres': [[7, 8], [12, 13]],\n",
       "             ',': [[9]],\n",
       "             'as': [[10]],\n",
       "             'this': [[11], [26]],\n",
       "             'to': [[14], [21]],\n",
       "             'the': [[15]],\n",
       "             'lettre': [[16, 17]],\n",
       "             'dothe': [[18]],\n",
       "             'pretende': [[19, 20]],\n",
       "             'shewe': [[22]],\n",
       "             ':': [[23]],\n",
       "             'but': [[24]],\n",
       "             'all': [[25]],\n",
       "             'was': [[27]],\n",
       "             'done': [[28]],\n",
       "             'in': [[29]],\n",
       "             'great': [[30]],\n",
       "             'mistery': [[31, 32]],\n",
       "             '.': [[33]]})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subwords_to_token_ids(ids2['input_ids'][0], tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9431324a-fe1c-4ae1-823b-199901221b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'God hath no suche bodyly membres, as this texte to the lettre dothe pretende to shewe: but all this was done in great mistery.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31b03729-322a-4fdf-a791-ba8850c1ad41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'god',\n",
       " 'hath',\n",
       " 'no',\n",
       " 'suche',\n",
       " 'body',\n",
       " '##ly',\n",
       " 'membr',\n",
       " '##es',\n",
       " ',',\n",
       " 'as',\n",
       " 'this',\n",
       " 'text',\n",
       " '##e',\n",
       " 'to',\n",
       " 'the',\n",
       " 'lett',\n",
       " '##re',\n",
       " 'dothe',\n",
       " 'pretend',\n",
       " '##e',\n",
       " 'to',\n",
       " 'shewe',\n",
       " ':',\n",
       " 'but',\n",
       " 'all',\n",
       " 'this',\n",
       " 'was',\n",
       " 'done',\n",
       " 'in',\n",
       " 'great',\n",
       " 'mister',\n",
       " '##y',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.convert_ids_to_tokens(ids['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d7b07a74-2fa7-4e0b-9abe-5e6f2cc39079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subwords_to_token_ids(ids, tokenizer, prefix='##'):\n",
    "    # for ids, k in tqdm.tqdm(zip(tokens['input_ids'], keyword)):\n",
    "    #     mapping = subwords_to_token_ids(ids, tokenizer)\n",
    "    #     subwords = tokenizer.convert_ids_to_tokens(ids)\n",
    "    #     for idxs in mapping[k]:\n",
    "    #         out = ''.join(subwords[i].lstrip('##') for i in idxs)\n",
    "    #         assert out == k, (out, k)\n",
    "    output = collections.defaultdict(list)\n",
    "    special = set(tokenizer.special_tokens_map.values())\n",
    "    subwords = tokenizer.convert_ids_to_tokens(ids)\n",
    "    ids, word = [], ''\n",
    "    for idx, subword in enumerate(subwords):\n",
    "        if subword in special:\n",
    "            continue\n",
    "        if subword.startswith(prefix):\n",
    "            word += subword[len(prefix):]\n",
    "            ids.append(idx)\n",
    "        else:\n",
    "            if word:\n",
    "                output[word].append(ids)\n",
    "            ids, word = [idx], subword\n",
    "    if word:\n",
    "        output[word].append(ids)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9a2152ea-5641-4aef-94a4-6e43505ecf0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quote</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>God hath no suche bodyly membres, as this text...</td>\n",
       "      <td>mistery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For we do it not actuallye in dede, but onlye ...</td>\n",
       "      <td>misterye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Whiche place is to be vnderstande in a mistery .</td>\n",
       "      <td>mistery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>At welles five licour I shal drawe Where al my...</td>\n",
       "      <td>mysteryes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The glorius modir Quhilk of hir natur consavit...</td>\n",
       "      <td>misteris</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               quote    keyword\n",
       "0  God hath no suche bodyly membres, as this text...    mistery\n",
       "1  For we do it not actuallye in dede, but onlye ...   misterye\n",
       "2   Whiche place is to be vnderstande in a mistery .    mistery\n",
       "3  At welles five licour I shal drawe Where al my...  mysteryes\n",
       "4  The glorius modir Quhilk of hir natur consavit...   misteris"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['quote', 'keyword']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fd37623b-a242-41d8-ba14-c2491c24c1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./Downloads/thesis final data.utf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fd9dd567-7993-4918-98fd-5b09b9ff04be",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = zip(*data[['Context before', 'Query term', 'Context after']].values)\n",
    "\n",
    "sents, keywords = [], []\n",
    "for a1, b1, c1 in zip(a, b, c):\n",
    "    sents.append(a1 + ' ' + b1 + ' '+ c1)\n",
    "    keywords.append(b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "14de44c9-62ee-4305-9bcd-84e9d643972c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a yellow colour . It was filtered and evaporated , when it left a quantity of emulsine . The yellow mass on the filter was treated with boiling alcohol , which became yellow , while the residue lost almost the whole',\n",
       " 'mass')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents[0], keywords[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2d540175-7150-4144-8de3-4d713d04cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = tok(list(sents[:5]), return_tensors='pt', padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cca74e9f-a5c1-45d2-9cff-20db8890d817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state', 'pooler_output'])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = m(**ids)\n",
    "output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f9e4850f-855e-40bb-812d-47cfee06943c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25]] -- mass -- a yellow colour . It was filtered and evaporated , when it left a quantity of emulsine . The yellow mass on the filter was treated with boiling alcohol , which became yellow , while the residue lost almost the whole\n",
      "[[21]] -- mass -- . In my paper on the Physical Properties of Ice this promise is fulfilled ; I have shown how a mass of compact ice may be liquefied by pressure , in parallel planes perpendicular to the direction of the force ,\n",
      "[[22]] -- mass -- cone in 7 minutes after the commencement of filling , which may be taken as the time in which the mass of iron in the cone had reached 21 Fahr. It was also found that the firm surrounding solid crust had\n",
      "[[22], [38]] -- mass -- perpendicularly towards that surface , saving an abatement that must be made for the inequality of pressure upon the central mass , when that is not in equilibrium . But if the central mass be infinitely , small , whether it\n",
      "[[22]] -- mass -- took place ; and , when this had subsided , the whole was poured into a proper vessel . The mass , when cold , was grayish-brown . Boiling distilled water was poured upon it ; and the brown residuum ,\n"
     ]
    }
   ],
   "source": [
    "for idx, keyword in enumerate(keywords[:5]):\n",
    "    mapping = subwords_to_token_ids(ids['input_ids'][idx], tok)\n",
    "    target = mapping[keyword]\n",
    "    print(target, \"--\", keyword, \"--\", sents[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d3c0596a-1c66-4c77-ac0f-359c514937d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'took': [[1]],\n",
       "             'place': [[2]],\n",
       "             ';': [[3], [41]],\n",
       "             'and': [[4], [42]],\n",
       "             ',': [[5], [11], [23], [26], [48]],\n",
       "             'when': [[6], [24]],\n",
       "             'this': [[7]],\n",
       "             'had': [[8]],\n",
       "             'subsided': [[9, 10]],\n",
       "             'the': [[12], [21], [43]],\n",
       "             'whole': [[13]],\n",
       "             'was': [[14], [27], [37]],\n",
       "             'poured': [[15], [38]],\n",
       "             'into': [[16]],\n",
       "             'a': [[17]],\n",
       "             'proper': [[18]],\n",
       "             'vessel': [[19]],\n",
       "             '.': [[20], [32]],\n",
       "             'mass': [[22]],\n",
       "             'cold': [[25]],\n",
       "             'grayish': [[28, 29]],\n",
       "             '-': [[30]],\n",
       "             'brown': [[31], [44]],\n",
       "             'boiling': [[33]],\n",
       "             'distilled': [[34, 35]],\n",
       "             'water': [[36]],\n",
       "             'upon': [[39]],\n",
       "             'it': [[40]],\n",
       "             'residuum': [[45, 46, 47]]})"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d67ce7e-5497-4f07-a990-4df64ddf69ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
